argparse_cfg:
  gpus: 
    bind_to: processor_cfg.gpus
    help: number of gpus
  work_dir: 
    bind_to: processor_cfg.work_dir
    help: the dir to save logs and models
    default: ./work_dir/recognition/st_gcn/kinetics-skeleton-dataset
  batch_size: 
    bind_to: processor_cfg.batch_size
  resume_from:
    bind_to: processor_cfg.resume_from
    help: the checkpoint file to resume from



processor_cfg: 
  name: '.processor.recognition.train'

  # model setting
  model_cfg:
    name: '.models.backbones.ST_GCN'
    in_channels: 3
    num_class: 400
    edge_importance_weighting: True
    graph_cfg:
      layout: 'openpose'
      strategy: 'spatial'
  loss_cfg:
    name: 'torch.nn.CrossEntropyLoss'

  # dataset setting
  dataset_cfg: 
    - name: '.datasets.recognition.SkeletonDataset'
      data_dir: ./data/Kinetics/skeleton-from-openpose/train
      random_choose: True
      random_move: True
      window_size: 150
      data_subscripts: cvfm->cfvm  # permute data
      normalization: True
      num_track: 2

    - name: '.datasets.recognition.SkeletonDataset'
      data_dir: ./data/Kinetics/skeleton-from-openpose/val
      data_subscripts: cvtm->ctvm  # permute data
      normalization: True
      num_track: 2


  # dataloader setting
  batch_size: 256
  gpus: 4

  # optimizer setting
  optimizer_cfg:
    name: 'torch.optim.SGD'
    lr: 0.1
    momentum: 0.9
    nesterov: true
    weight_decay: 0.0001

  # runtime setting
  workflow: [['train', 5], ['val', 1]]
  work_dir:
  workers: 32
  log_level: 0
  total_epochs: 50
  training_hooks:
    lr_config:
      policy: 'step'
      step: [20, 30, 40, 50]
    log_config:
      interval: 100
      hooks:
        - type: TextLoggerHook
    checkpoint_config:
      interval: 5
    optimizer_config:
  resume_from:
  load_from: